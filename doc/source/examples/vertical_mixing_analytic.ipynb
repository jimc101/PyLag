{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D turbulent mixing\n",
    "\n",
    "In this example, we look at turbulent mixing in 1D using an analytic diffusivity profile to drive particle movement. In so doing, we examine the ability of different numerical schemes to reproduce the Well Mixed Condition (WMC), which states that if a tracer is initially well-mixed it will remain so over time (Thomson, 1987). The example illustrates a problem that was identified in several models of turbulent mixing back in the late 1990s. As described by Visser (1997), the problem related to the inability of standard (\"naive\") random walk models to reproduce the WMC in spatially inhomogeneous diffusivity fields. Visser (1997) derived a formulation that corrected the problem, which later became widely used in particle tracking models for marine applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background theory\n",
    "\n",
    "In 1D, and without advection, a standard (\"naive\") random walk model computes changes in particle positions using an equation of the form:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    z_{n+1} = z_{n} +  \\left(2 K \\left(z, t \\right)\\right)^{1/2} \\Delta W_{n} \\qquad \\text{Naive scheme,}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $K$ is the vertical eddy diffusivity and $\\Delta W$ is an incremental Wiener process that builds stochasticity into the model. While such a model works fine in spatially homogeneous diffusivity fields, it breaks in spatially inhomogeneous fields, as particles tend to accumulate in regions of low diffusivity. Grawe et al (2012) presented multiple numerical approximations, including that derived by Visser (1997), which correct for the artificial build up of particles in regions of low diffusivity through the inclusion of a deterministic drift term. Three of these have been implemented within PyLag. Without advection, and while taking the form of the diffusivity profile to be invariant with respect time, these are:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    z_{n+1} = z_{n} +  \\left(\\dfrac{\\partial K\\left(z\\right)}{\\partial z}\\right)\\Delta t + \\left(2 K\\left(z\\right)\\right)^{1/2} \\Delta W_n \\qquad \\text{Euler Scheme,}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    z_{n+1} = z_{n} +  \\left(\\dfrac{\\partial K\\left(z\\right)}{\\partial z}\\right)\\Delta t + \\left(2 K\\left(\\widetilde{z}\\right)\\right)^{1/2} \\Delta W_n \\qquad \\text{Visser Scheme,}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "     z_{n+1} = z_{n} + \\frac{1}{2} \\frac{\\partial K\\left(z\\right)}{\\partial z} \\left(\\Delta W_{n}^{2} + \\Delta t \\right) + \\left(2 K\\left(z\\right)\\right)^{1/2} \\Delta W_{n} \\qquad \\text{Milstein Scheme.}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The Euler and Visser schemes are identical, with the exception that in the Visser scheme, $K$ is evaluated at a position:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "     \\widetilde{z} = z_{n} + \\frac{\\Delta t}{2} \\frac{\\partial K\\left(z\\right)}{\\partial z}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In the language of stochastic differential equations, a given appoximating process is said to converge in either a \"strong\" or a \"weak\" sense: strong convergence relates to how closely the approximating process reproduces sample paths; weak convergence to how closely some function of the value of the process is reproduced, for example, the mean particle position. The Euler and Visser schemes converge with order $\\left(\\Delta t\\right)^{1/2}$ in the strong sense, and with order $\\Delta t$ in the weak sense. In contrast, the Milstein scheme converges with order $\\Delta t$ in both the strong and weak sense. Here we are insterested in the mean position of particles within the water column, meaning we are most interested in each scheme's convergence in the weak sense. Given this, we expect each approximation to perform equally well.\n",
    "\n",
    "We will test this expectation below using the same diffusivity profile that Visser (1997) used. The diffusivity profile is given by the analytic experession:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    k(z) = 0.001 + 0.0136245 z - 0.00263245 z^{2} + 2.11875 \\times 10^{-4} z^{3} -\n",
    "    8.65898 \\times 10^{-6} z^{4} + 1.7623 \\times 10^{-7} z^{5} - 1.40918 \\times 10^{-9} z^{6}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $k(z)$ is the vertical diffusivity as a function of depth, $z$. Depth is measured up from the sea floor ($z = 0$m) to the sea surface ($z = 40$m). A plot of the diffusivity profile is shown below. As in previous examples using analytic expressions, we encode the profile within an object of type `DataReader`, which allows it to be used with *Pylag* in the same way as any other `DataReader` object. In the following, we instantiate a new `DataReader` object and plot the analytic profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pylag.particle_cpp_wrapper import ParticleSmartPtr\n",
    "from pylag.mock import MockVerticalDiffusivityDataReader\n",
    "import pylag.random as random\n",
    "\n",
    "from pylagtools.plot import create_figure\n",
    "\n",
    "# Seed the PRNG\n",
    "random.seed()\n",
    "\n",
    "# Create data reader\n",
    "data_reader = MockVerticalDiffusivityDataReader()\n",
    "\n",
    "# Get z min and max. We give dummy values for the time and\n",
    "# particle arguments, which in this example, aren't used to\n",
    "# compute z_min or z_max.\n",
    "z_min = data_reader.get_zmin_wrapper(0.0, ParticleSmartPtr())\n",
    "z_max = data_reader.get_zmax_wrapper(0.0, ParticleSmartPtr())\n",
    "n_z_levels = 41\n",
    "\n",
    "# Reference heights above the sea bed\n",
    "z_levels = np.linspace(z_min, z_max, n_z_levels, dtype=float)\n",
    "\n",
    "# Generate the profile for plotting\n",
    "Kh = np.empty_like(z_levels)\n",
    "for i, z in enumerate(z_levels):\n",
    "    Kh[i] = data_reader.get_vertical_eddy_diffusivity_analytic(z)\n",
    "\n",
    "# Create figure for plotting\n",
    "font_size = 15\n",
    "fig, ax = create_figure(figure_size=(10., 10.), font_size=font_size)\n",
    "    \n",
    "# Plot the diffusivity profile\n",
    "ax.plot(Kh*100., z_levels, 'b')\n",
    "ax.set_title('Diffusivity profile', fontsize=font_size)\n",
    "ax.set_xlabel(r'K x 10$^{2}$ (m$^{2}$ s$^{-1}$)', fontsize=font_size)\n",
    "ax.set_ylabel('Height above sea bed (m)', fontsize=font_size)\n",
    "ax.set_ylim(ymin=z_min, ymax=z_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The profile is designed to reflect observed diffusivity profiles found in stratified, shallow water environments, where the diffusivity is often high in the surface and bottom layers, and low in the middle of the water column.\n",
    "\n",
    "We will evaluate the different schemes using the WMC. Brickman and Smith (2003) outlined an algorithm for demonstrating the WMC, which involves running an ensemble of $M$ model simulations, each involving $N_{p}$ particles, that are initially uniformly distributed in space. The same basic algorithm is followed here. Each simulation uses its own, random particle seed of $1000$ particles with initial $z$ positions uniformly distributed between the sea floor and the sea surface. Each simulation is run for 4 hrs using a time step of 6 s, and 5 simulations are run in total. At each time point, the concentration of particles is computed at $N_{z}$ (=41) equally spaced z-levels using an Epanechnikov Kernel Density Estimator (KDE) to compute particle concentrations. The time mean concentration $\\overline{C(z)}$ at each depth level is then computed for each member of the ensemble. Finally, the ensemble mean concentration $\\left\\langle\\overline{C(z)}\\right\\rangle$ is computed across the full ensemble. The WMC is said to be satisfied if the ensemble mean at each depth level lies within one standard deviation of the initial particle concentration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the particle tracking model\n",
    "\n",
    "The experiment requires us to run an ensemble of simulations. Furthermore, we want to be able to do this using different numerical integration schemes. To make things a little cleaner, we will use a helper function that will run a single simulation and return particle positions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "from pylag.mock import MockOneDNumMethod\n",
    "\n",
    "\n",
    "def run_particle_simulation(model_name):\n",
    "    \"\"\"Run a single simulation\n",
    "\n",
    "    An initial particle seed is created. Particle starting depths are uniformly\n",
    "    distributed over the vertical grid. Particle trajectories and final positions\n",
    "    are then computed by integrating the model forward in time using the named\n",
    "    iterative method.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_name: str\n",
    "        Name of the iterative method under test\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    particle_depths: ndarray[# particles, time]\n",
    "       2D numpy array of particle depths\n",
    "    \"\"\"\n",
    "    # Create a run config\n",
    "    config = ConfigParser()\n",
    "    \n",
    "    # Specify that we are not restoring to a fixed depth\n",
    "    config.add_section(\"SIMULATION\")\n",
    "    config.set(\"SIMULATION\", \"depth_restoring\", \"False\")\n",
    "    config.set(\"SIMULATION\", \"fixed_depth\", \"0.0\")\n",
    "    \n",
    "    # Set the coordinate system, which here is a simple cartesian coordinate system\n",
    "    config.add_section('OCEAN_CIRCULATION_MODEL')\n",
    "    config.set('OCEAN_CIRCULATION_MODEL', 'coordinate_system', 'cartesian')\n",
    "    \n",
    "    # Specify the numerical scheme we will use\n",
    "    config.add_section(\"NUMERICS\")\n",
    "    config.set(\"NUMERICS\", \"num_method\", \"standard\")\n",
    "    config.set(\"NUMERICS\", \"iterative_method\", model_name)\n",
    "    config.set(\"NUMERICS\", \"time_step_diff\", str(time_step))\n",
    "\n",
    "    # Use a reflecting vertical boundary condition\n",
    "    config.add_section(\"BOUNDARY_CONDITIONS\")\n",
    "    config.set(\"BOUNDARY_CONDITIONS\", \"vert_bound_cond\", \"reflecting\")\n",
    "\n",
    "    # Create test object using the run config\n",
    "    num_method = MockOneDNumMethod(config)\n",
    "\n",
    "    # Initial z positions - uniformly distributed in the first instance\n",
    "    z_positions = []\n",
    "    for i in range(n_particles):\n",
    "        z_positions.append(random.uniform(z_min, z_max))\n",
    "\n",
    "    # Create array in which to store particle depths\n",
    "    particle_depths = np.empty((n_times, n_particles), dtype=float)\n",
    "\n",
    "    # Integrate the model forward in time\n",
    "    for t_idx, t in enumerate(time):\n",
    "        # Save z positions for the last time point\n",
    "        particle_depths[t_idx, :] = z_positions[:]\n",
    "\n",
    "        # Compute new z positions\n",
    "        z_positions[:] = num_method.step(data_reader, t, z_positions)[:]\n",
    "\n",
    "    return particle_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed things up a bit, we use an object of type MockOneDNumMethod to help manage the integration. While not strictly necessary, it cythonizes the particle loop, which yields a speed up over doing the same operation in python. Note the function references a time array, which we are yet to create. We set these below, then run ensemble simulations using different numerical approximation techniques. The data from each method are saved into separate arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time variables (s)\n",
    "time_start = 0.0\n",
    "time_end = 3600.0*4\n",
    "time_step = 6.0\n",
    "time = np.arange(time_start, time_end, time_step)\n",
    "n_times = time.shape[0]\n",
    "\n",
    "# No. of particles to use in each simulation\n",
    "n_particles = 1000\n",
    "\n",
    "# No. of trials to use in each ensemble\n",
    "n_trials = 5\n",
    "\n",
    "# Store outputs in a dictionary\n",
    "particle_data = {'Diff_Naive_1D': np.empty((n_trials, n_times, n_particles), dtype=float),\n",
    "                 'Diff_Euler_1D': np.empty((n_trials, n_times, n_particles), dtype=float),\n",
    "                 'Diff_Visser_1D': np.empty((n_trials, n_times, n_particles), dtype=float),\n",
    "                 'Diff_Milstein_1D': np.empty((n_trials, n_times, n_particles), dtype=float)}\n",
    "\n",
    "# Run the particle ensembles\n",
    "for method, data in particle_data.items():\n",
    "    for i in range(n_trials):\n",
    "        data[i, :, :] = run_particle_simulation(method)[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the result\n",
    "\n",
    "We can quickly visualise the output using 2D histograms to highlight the position of particles throughout the water column and how these change with time. We do this for one of the trials for each method under test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylagtools.plot import create_cbar_ax\n",
    "\n",
    "# Grids for plotting using pcolormesh\n",
    "bin_edges = range(int(z_max-z_min) + 1)\n",
    "time_out = np.arange(time_start-time_step/2., time_end + time_step/2., time_step)/3600.0\n",
    "depth_out = np.array(bin_edges)\n",
    "time_grid, depth_grid = np.meshgrid(time_out, depth_out)\n",
    "\n",
    "# Create figure\n",
    "fig, axarr = plt.subplots(nrows=1,ncols=4, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Store plots and calculated concentrations in lists\n",
    "concentrations = []\n",
    "plots = []\n",
    "\n",
    "# Loop over each method and plot the concentration of particles\n",
    "for i, (name, data) in enumerate(particle_data.items()):\n",
    "    concentration = np.empty((len(bin_edges)-1, n_times))\n",
    "    for j in range(n_times):\n",
    "        hist, bins = np.histogram(data[0,j,:], bins=bin_edges)\n",
    "        concentration[:,j] = hist\n",
    "    concentrations.append(concentration)\n",
    "\n",
    "    plot = axarr[i].pcolormesh(time_grid, depth_grid, concentration, vmin=0, vmax=70)\n",
    "    plots.append(plot)\n",
    "    \n",
    "    axarr[i].set_title('{}'.format(name), fontsize=font_size)\n",
    "    axarr[i].set_xlabel('Time (h)', fontsize=font_size)\n",
    "    axarr[i].tick_params(axis='both', which='major', labelsize=font_size)\n",
    "    axarr[i].tick_params(axis='both', which='minor', labelsize=font_size)\n",
    "    \n",
    "axarr[0].set_ylabel('Height above sea bed (m)', fontsize=font_size)\n",
    "\n",
    "# Add colour bar to the last plot\n",
    "cax = create_cbar_ax(axarr[3])\n",
    "cbar = fig.colorbar(plots[3], cax=cax)\n",
    "cbar.ax.tick_params(labelsize=font_size)\n",
    "cbar.set_label('Concentration (#/m)', fontsize=font_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure, the problems with the \"naive\" scheme become immediately apparent, with uneven particle concentrations throughout the water column. Comparing with the diffusivity profile above, it is clear particles have accumulated in regiond os low diffusivity, as explained by Visser (1997). In qualitative terms, the other three schemes exhibit a more even particle distribution.\n",
    "\n",
    "We can quantitatively test whether each scheme satisfies the WMC in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqt_fit import kde, kde_methods, kernels\n",
    "\n",
    "# Dictionary in which to store mean concentrations as a function of depth\n",
    "means = {}\n",
    "\n",
    "# Dictionary in which to store std's as a function of depth\n",
    "stds = {}\n",
    "\n",
    "# Compute KDE, means and std's for ...\n",
    "#   - All methods\n",
    "#   - All trials\n",
    "#   - All time points\n",
    "for i, (name, data) in enumerate(particle_data.items()):\n",
    "    particle_kde = np.empty((n_trials, n_times, n_z_levels), dtype=float)\n",
    "    for i in range(n_trials):\n",
    "        for j in range(n_times):\n",
    "            est = kde.KDE1D(data[i, j, :], lower=z_min, upper=z_max,\n",
    "                    method=kde_methods.reflection, kernel=kernels.Epanechnikov())\n",
    "            particle_kde[i, j, :] = n_particles * est(z_levels)\n",
    "\n",
    "    means[name] = np.mean(particle_kde, axis=(0,1))\n",
    "    stds[name] = np.std(particle_kde, axis=(0,1))\n",
    "\n",
    "# Compute reference particle concentration (#/m)\n",
    "ref_conc = n_particles/float(n_z_levels - 1)\n",
    "\n",
    "# Create figure\n",
    "fig, axarr = plt.subplots(nrows=1,ncols=4, figsize=(12, 6), sharey=True)\n",
    "\n",
    "# Plot means and stds\n",
    "for idx, name in enumerate(particle_data.keys()):\n",
    "    axarr[idx].errorbar(means[name], z_levels, xerr=stds[name], fmt='-o', c='r')\n",
    "    axarr[idx].axvline(ref_conc, ymin=0, ymax=1, c='k', linestyle='--')\n",
    "    axarr[idx].set_title(name, fontsize=font_size)\n",
    "    axarr[idx].set_xlabel('Particle conc (#/m)', fontsize=font_size)\n",
    "    if name == 'Diff_Naive_1D':\n",
    "        # Naive is known to fail so we set broarder xlims\n",
    "        axarr[idx].set_xlim(xmin=0., xmax=2.*ref_conc)\n",
    "    else:\n",
    "        axarr[idx].set_xlim(xmin=ref_conc - ref_conc/4., xmax=ref_conc + ref_conc/4.)\n",
    "    axarr[idx].set_ylim(ymin=z_min, ymax=z_max)\n",
    "\n",
    "# Tidy up x and y tick labels\n",
    "for ax in axarr:\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=font_size)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure, the vertical black dashed line marks the initial particle concentration, while in red is shown the mean particle concentration $\\pm$ one standard deviation. The failure of the Naive scheme to satisfy the WMC can be clearly seen (note the different x-axis scale for the Naive scheme). Meanwhile, all the other schemes successfully pass the test for this particular analytic profile. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
